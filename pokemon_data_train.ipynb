{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train pokemon data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='pokemon_valid',\n",
       "          thing_classes=['gengar'],\n",
       "          json_file='../../datasets/pokemon/v5/valid/_annotations.coco.json',\n",
       "          image_root='../../datasets/pokemon/v5/valid')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detectron2.data.datasets import register_coco_instances, load_coco_json\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "DATASET_DIR=\"../../datasets/pokemon/v5/\"\n",
    "COCO_JSON_FILE_NAME=\"_annotations.coco.json\"\n",
    "\n",
    "TRAIN_JSON_PATH = DATASET_DIR + \"train/\" +COCO_JSON_FILE_NAME\n",
    "TRAIN_IMG_PATH = DATASET_DIR + \"train\"\n",
    "\n",
    "VALID_JSON_PATH = DATASET_DIR + \"valid/\" +COCO_JSON_FILE_NAME\n",
    "VALID_IMG_PATH = DATASET_DIR + \"valid\"\n",
    "\n",
    "TEST_JSON_PATH = DATASET_DIR + \"test/\" +COCO_JSON_FILE_NAME\n",
    "TEST_IMG_PATH = DATASET_DIR + \"test\"\n",
    "\n",
    "# register_coco_instances(\"pokemon_train\", {}, TRAIN_JSON_PATH, TRAIN_IMG_PATH)\n",
    "# register_coco_instances(\"pokemon_valid\", {}, VALID_JSON_PATH, VALID_IMG_PATH)\n",
    "# register_coco_instances(\"pokemon_test\", {}, TEST_JSON_PATH, TEST_IMG_PATH)\n",
    "\n",
    "DatasetCatalog.register(\"pokemon_train\", lambda: load_coco_json(TRAIN_JSON_PATH, TRAIN_IMG_PATH,\"pokemon_train\"))\n",
    "MetadataCatalog.get(\"pokemon_train\").set(thing_classes=[\"gengar\"],json_file=TRAIN_JSON_PATH,image_root=TRAIN_IMG_PATH)\n",
    "\n",
    "DatasetCatalog.register(\"pokemon_valid\", lambda: load_coco_json(VALID_JSON_PATH, VALID_IMG_PATH,\"pokemon_valid\"))\n",
    "MetadataCatalog.get(\"pokemon_valid\").set(thing_classes=[\"gengar\"],json_file=VALID_JSON_PATH,image_root=VALID_IMG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random,time\n",
    "import cv2\n",
    "from detectron2.data.datasets import load_coco_json\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "dataset_train_dicts = load_coco_json(TRAIN_JSON_PATH, TRAIN_IMG_PATH, \"pokemon_train\")\n",
    "pokemon_metadata = MetadataCatalog.get(\"pokemon_train\")\n",
    "\n",
    "for d in random.sample(dataset_train_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=pokemon_metadata, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    cv2.imshow(str(round(time.time()*1000))+'.jpg', out.get_image()[:, :, ::-1])\n",
    "    if cv2.waitKey(0) == 27:\n",
    "        break  # esc to quit\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"pokemon_train\")\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 600    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/09 14:25:11 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[08/09 14:25:11 d2.data.datasets.coco]: \u001b[0mLoaded 111 images in COCO format from ../../datasets/pokemon/v5/train/_annotations.coco.json\n",
      "\u001b[32m[08/09 14:25:11 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 111 images left.\n",
      "\u001b[32m[08/09 14:25:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/09 14:25:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/09 14:25:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[08/09 14:25:11 d2.data.common]: \u001b[0mSerializing 111 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/09 14:25:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n",
      "\u001b[32m[08/09 14:25:11 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[08/09 14:25:11 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/09 14:25:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/09 14:25:14 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 19  total_loss: 1.813  loss_cls: 0.6604  loss_box_reg: 0.4634  loss_mask: 0.6908  loss_rpn_cls: 0.003779  loss_rpn_loc: 0.009138    time: 0.1754  last_time: 0.1589  data_time: 0.0059  last_data_time: 0.0023   lr: 4.9953e-06  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:18 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 39  total_loss: 1.788  loss_cls: 0.6071  loss_box_reg: 0.4377  loss_mask: 0.6787  loss_rpn_cls: 0.001399  loss_rpn_loc: 0.004671    time: 0.1746  last_time: 0.1472  data_time: 0.0023  last_data_time: 0.0022   lr: 9.9902e-06  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:21 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 59  total_loss: 1.684  loss_cls: 0.507  loss_box_reg: 0.4813  loss_mask: 0.656  loss_rpn_cls: 0.004437  loss_rpn_loc: 0.00902    time: 0.1764  last_time: 0.1884  data_time: 0.0021  last_data_time: 0.0020   lr: 1.4985e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:25 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 79  total_loss: 1.51  loss_cls: 0.4001  loss_box_reg: 0.4506  loss_mask: 0.6238  loss_rpn_cls: 0.005438  loss_rpn_loc: 0.005832    time: 0.1756  last_time: 0.1840  data_time: 0.0021  last_data_time: 0.0021   lr: 1.998e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:28 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 99  total_loss: 1.397  loss_cls: 0.3322  loss_box_reg: 0.5094  loss_mask: 0.5824  loss_rpn_cls: 0.003211  loss_rpn_loc: 0.005877    time: 0.1744  last_time: 0.1492  data_time: 0.0024  last_data_time: 0.0026   lr: 2.4975e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:32 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 119  total_loss: 1.228  loss_cls: 0.2717  loss_box_reg: 0.4438  loss_mask: 0.5468  loss_rpn_cls: 0.003346  loss_rpn_loc: 0.01351    time: 0.1737  last_time: 0.1814  data_time: 0.0025  last_data_time: 0.0029   lr: 2.997e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:35 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 139  total_loss: 1.143  loss_cls: 0.2437  loss_box_reg: 0.3686  loss_mask: 0.4905  loss_rpn_cls: 0.003894  loss_rpn_loc: 0.007804    time: 0.1727  last_time: 0.1764  data_time: 0.0026  last_data_time: 0.0025   lr: 3.4965e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:39 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 159  total_loss: 1.272  loss_cls: 0.2607  loss_box_reg: 0.5704  loss_mask: 0.4178  loss_rpn_cls: 0.001599  loss_rpn_loc: 0.005357    time: 0.1739  last_time: 0.1669  data_time: 0.0023  last_data_time: 0.0018   lr: 3.996e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:42 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 179  total_loss: 0.9507  loss_cls: 0.1655  loss_box_reg: 0.4059  loss_mask: 0.3699  loss_rpn_cls: 0.001748  loss_rpn_loc: 0.007888    time: 0.1741  last_time: 0.1695  data_time: 0.0024  last_data_time: 0.0022   lr: 4.4955e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:46 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 199  total_loss: 0.9669  loss_cls: 0.1579  loss_box_reg: 0.4618  loss_mask: 0.3081  loss_rpn_cls: 0.002132  loss_rpn_loc: 0.00684    time: 0.1747  last_time: 0.1795  data_time: 0.0025  last_data_time: 0.0025   lr: 4.995e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:50 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 219  total_loss: 0.9608  loss_cls: 0.1426  loss_box_reg: 0.5018  loss_mask: 0.2866  loss_rpn_cls: 0.001021  loss_rpn_loc: 0.00623    time: 0.1754  last_time: 0.1694  data_time: 0.0025  last_data_time: 0.0027   lr: 5.4945e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:53 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 239  total_loss: 0.898  loss_cls: 0.1348  loss_box_reg: 0.5005  loss_mask: 0.2453  loss_rpn_cls: 0.001013  loss_rpn_loc: 0.007382    time: 0.1763  last_time: 0.1939  data_time: 0.0024  last_data_time: 0.0023   lr: 5.994e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:25:57 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 259  total_loss: 0.8569  loss_cls: 0.1193  loss_box_reg: 0.4938  loss_mask: 0.2023  loss_rpn_cls: 0.000813  loss_rpn_loc: 0.007432    time: 0.1770  last_time: 0.2013  data_time: 0.0023  last_data_time: 0.0022   lr: 6.4935e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:01 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 279  total_loss: 0.6249  loss_cls: 0.07432  loss_box_reg: 0.3586  loss_mask: 0.1461  loss_rpn_cls: 0.0002421  loss_rpn_loc: 0.006377    time: 0.1776  last_time: 0.1813  data_time: 0.0024  last_data_time: 0.0023   lr: 6.993e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:04 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 299  total_loss: 0.5998  loss_cls: 0.07415  loss_box_reg: 0.3983  loss_mask: 0.1505  loss_rpn_cls: 0.0005442  loss_rpn_loc: 0.007463    time: 0.1775  last_time: 0.2011  data_time: 0.0022  last_data_time: 0.0023   lr: 7.4925e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:08 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 319  total_loss: 0.523  loss_cls: 0.06459  loss_box_reg: 0.3141  loss_mask: 0.128  loss_rpn_cls: 0.0002807  loss_rpn_loc: 0.008321    time: 0.1775  last_time: 0.1724  data_time: 0.0024  last_data_time: 0.0021   lr: 7.992e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:11 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 339  total_loss: 0.379  loss_cls: 0.05404  loss_box_reg: 0.2234  loss_mask: 0.1093  loss_rpn_cls: 0.0001831  loss_rpn_loc: 0.01048    time: 0.1772  last_time: 0.1602  data_time: 0.0023  last_data_time: 0.0023   lr: 8.4915e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:15 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 359  total_loss: 0.4526  loss_cls: 0.06104  loss_box_reg: 0.2346  loss_mask: 0.1337  loss_rpn_cls: 0.0001595  loss_rpn_loc: 0.006295    time: 0.1766  last_time: 0.1408  data_time: 0.0023  last_data_time: 0.0021   lr: 8.991e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:18 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 379  total_loss: 0.3474  loss_cls: 0.05558  loss_box_reg: 0.194  loss_mask: 0.09176  loss_rpn_cls: 0.0002816  loss_rpn_loc: 0.006292    time: 0.1764  last_time: 0.1722  data_time: 0.0024  last_data_time: 0.0022   lr: 9.4905e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:22 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 399  total_loss: 0.3202  loss_cls: 0.04792  loss_box_reg: 0.1759  loss_mask: 0.1033  loss_rpn_cls: 0.0004514  loss_rpn_loc: 0.008741    time: 0.1762  last_time: 0.1838  data_time: 0.0023  last_data_time: 0.0021   lr: 9.99e-05  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:25 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 419  total_loss: 0.3197  loss_cls: 0.05092  loss_box_reg: 0.1675  loss_mask: 0.08365  loss_rpn_cls: 0.000106  loss_rpn_loc: 0.005958    time: 0.1765  last_time: 0.1927  data_time: 0.0029  last_data_time: 0.0024   lr: 0.0001049  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:29 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 439  total_loss: 0.2503  loss_cls: 0.03885  loss_box_reg: 0.1254  loss_mask: 0.07848  loss_rpn_cls: 0.0002013  loss_rpn_loc: 0.006064    time: 0.1761  last_time: 0.1800  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00010989  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:32 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 459  total_loss: 0.2433  loss_cls: 0.04231  loss_box_reg: 0.14  loss_mask: 0.07804  loss_rpn_cls: 7.812e-05  loss_rpn_loc: 0.006234    time: 0.1758  last_time: 0.1679  data_time: 0.0026  last_data_time: 0.0023   lr: 0.00011489  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:36 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 479  total_loss: 0.2617  loss_cls: 0.03624  loss_box_reg: 0.1302  loss_mask: 0.08043  loss_rpn_cls: 0.0002148  loss_rpn_loc: 0.00387    time: 0.1756  last_time: 0.1669  data_time: 0.0026  last_data_time: 0.0028   lr: 0.00011988  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:39 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 499  total_loss: 0.2298  loss_cls: 0.03589  loss_box_reg: 0.09709  loss_mask: 0.08132  loss_rpn_cls: 0.0002314  loss_rpn_loc: 0.006559    time: 0.1758  last_time: 0.1849  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00012488  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:43 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 519  total_loss: 0.2077  loss_cls: 0.02603  loss_box_reg: 0.08366  loss_mask: 0.06839  loss_rpn_cls: 0.0001624  loss_rpn_loc: 0.007312    time: 0.1761  last_time: 0.1958  data_time: 0.0026  last_data_time: 0.0027   lr: 0.00012987  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:46 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 539  total_loss: 0.223  loss_cls: 0.03354  loss_box_reg: 0.08766  loss_mask: 0.08307  loss_rpn_cls: 0.0002428  loss_rpn_loc: 0.005112    time: 0.1762  last_time: 0.1655  data_time: 0.0023  last_data_time: 0.0021   lr: 0.00013487  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:50 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 559  total_loss: 0.2112  loss_cls: 0.04096  loss_box_reg: 0.09153  loss_mask: 0.07226  loss_rpn_cls: 0.0001577  loss_rpn_loc: 0.005072    time: 0.1765  last_time: 0.1648  data_time: 0.0022  last_data_time: 0.0023   lr: 0.00013986  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:54 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 579  total_loss: 0.2115  loss_cls: 0.03641  loss_box_reg: 0.09752  loss_mask: 0.07772  loss_rpn_cls: 0.0003701  loss_rpn_loc: 0.005341    time: 0.1764  last_time: 0.1724  data_time: 0.0022  last_data_time: 0.0025   lr: 0.00014486  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:26:57 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 599  total_loss: 0.2049  loss_cls: 0.03071  loss_box_reg: 0.08363  loss_mask: 0.08516  loss_rpn_cls: 0.0001257  loss_rpn_loc: 0.004322    time: 0.1764  last_time: 0.1556  data_time: 0.0025  last_data_time: 0.0019   lr: 0.00014985  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:01 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 619  total_loss: 0.1733  loss_cls: 0.02775  loss_box_reg: 0.06996  loss_mask: 0.0622  loss_rpn_cls: 7.453e-05  loss_rpn_loc: 0.003534    time: 0.1761  last_time: 0.1603  data_time: 0.0023  last_data_time: 0.0025   lr: 0.00015485  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:04 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 639  total_loss: 0.1914  loss_cls: 0.03217  loss_box_reg: 0.08606  loss_mask: 0.06362  loss_rpn_cls: 0.0001151  loss_rpn_loc: 0.004806    time: 0.1759  last_time: 0.1755  data_time: 0.0023  last_data_time: 0.0020   lr: 0.00015984  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:07 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 659  total_loss: 0.1885  loss_cls: 0.02422  loss_box_reg: 0.07641  loss_mask: 0.07426  loss_rpn_cls: 0.0001103  loss_rpn_loc: 0.004302    time: 0.1756  last_time: 0.1752  data_time: 0.0024  last_data_time: 0.0019   lr: 0.00016484  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:11 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 679  total_loss: 0.1881  loss_cls: 0.03535  loss_box_reg: 0.09127  loss_mask: 0.07586  loss_rpn_cls: 8.557e-05  loss_rpn_loc: 0.005643    time: 0.1754  last_time: 0.1876  data_time: 0.0022  last_data_time: 0.0020   lr: 0.00016983  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:14 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 699  total_loss: 0.1781  loss_cls: 0.02574  loss_box_reg: 0.07744  loss_mask: 0.06585  loss_rpn_cls: 0.0001213  loss_rpn_loc: 0.005633    time: 0.1753  last_time: 0.1649  data_time: 0.0023  last_data_time: 0.0021   lr: 0.00017483  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:18 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 719  total_loss: 0.1803  loss_cls: 0.02535  loss_box_reg: 0.07539  loss_mask: 0.05975  loss_rpn_cls: 0.0001812  loss_rpn_loc: 0.00435    time: 0.1757  last_time: 0.1742  data_time: 0.0026  last_data_time: 0.0029   lr: 0.00017982  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:22 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 739  total_loss: 0.1699  loss_cls: 0.02909  loss_box_reg: 0.06669  loss_mask: 0.06349  loss_rpn_cls: 0.0001004  loss_rpn_loc: 0.004978    time: 0.1758  last_time: 0.2033  data_time: 0.0025  last_data_time: 0.0025   lr: 0.00018482  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:25 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 759  total_loss: 0.1712  loss_cls: 0.02736  loss_box_reg: 0.07472  loss_mask: 0.06286  loss_rpn_cls: 0.0004678  loss_rpn_loc: 0.00402    time: 0.1761  last_time: 0.1579  data_time: 0.0025  last_data_time: 0.0019   lr: 0.00018981  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:29 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 779  total_loss: 0.1584  loss_cls: 0.01965  loss_box_reg: 0.06855  loss_mask: 0.06087  loss_rpn_cls: 6.229e-05  loss_rpn_loc: 0.0035    time: 0.1761  last_time: 0.1602  data_time: 0.0024  last_data_time: 0.0019   lr: 0.00019481  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:33 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 799  total_loss: 0.1526  loss_cls: 0.0247  loss_box_reg: 0.06805  loss_mask: 0.06391  loss_rpn_cls: 3.282e-05  loss_rpn_loc: 0.003564    time: 0.1763  last_time: 0.1709  data_time: 0.0026  last_data_time: 0.0027   lr: 0.0001998  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:36 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 819  total_loss: 0.1658  loss_cls: 0.0221  loss_box_reg: 0.06852  loss_mask: 0.06302  loss_rpn_cls: 8.027e-05  loss_rpn_loc: 0.006301    time: 0.1766  last_time: 0.1977  data_time: 0.0025  last_data_time: 0.0027   lr: 0.0002048  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:40 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 839  total_loss: 0.1691  loss_cls: 0.02172  loss_box_reg: 0.07214  loss_mask: 0.06135  loss_rpn_cls: 8.167e-05  loss_rpn_loc: 0.0048    time: 0.1767  last_time: 0.1988  data_time: 0.0024  last_data_time: 0.0024   lr: 0.00020979  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:44 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 859  total_loss: 0.1487  loss_cls: 0.01983  loss_box_reg: 0.06061  loss_mask: 0.06045  loss_rpn_cls: 9.87e-05  loss_rpn_loc: 0.003634    time: 0.1769  last_time: 0.1799  data_time: 0.0024  last_data_time: 0.0020   lr: 0.00021479  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:48 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 879  total_loss: 0.1383  loss_cls: 0.01781  loss_box_reg: 0.05122  loss_mask: 0.06436  loss_rpn_cls: 6.382e-05  loss_rpn_loc: 0.004089    time: 0.1771  last_time: 0.1859  data_time: 0.0022  last_data_time: 0.0020   lr: 0.00021978  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:51 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 899  total_loss: 0.1532  loss_cls: 0.02083  loss_box_reg: 0.05762  loss_mask: 0.0624  loss_rpn_cls: 3.859e-05  loss_rpn_loc: 0.003827    time: 0.1771  last_time: 0.1762  data_time: 0.0023  last_data_time: 0.0024   lr: 0.00022478  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:55 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 919  total_loss: 0.1379  loss_cls: 0.01872  loss_box_reg: 0.06052  loss_mask: 0.0586  loss_rpn_cls: 8.717e-05  loss_rpn_loc: 0.003265    time: 0.1771  last_time: 0.1550  data_time: 0.0022  last_data_time: 0.0022   lr: 0.00022977  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:27:58 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 939  total_loss: 0.148  loss_cls: 0.01732  loss_box_reg: 0.05557  loss_mask: 0.05703  loss_rpn_cls: 7.822e-05  loss_rpn_loc: 0.004002    time: 0.1771  last_time: 0.1778  data_time: 0.0024  last_data_time: 0.0021   lr: 0.00023477  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:28:02 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 959  total_loss: 0.1467  loss_cls: 0.01901  loss_box_reg: 0.06055  loss_mask: 0.05919  loss_rpn_cls: 9.914e-05  loss_rpn_loc: 0.003723    time: 0.1771  last_time: 0.1626  data_time: 0.0024  last_data_time: 0.0022   lr: 0.00023976  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:28:05 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 979  total_loss: 0.1404  loss_cls: 0.02007  loss_box_reg: 0.05789  loss_mask: 0.05681  loss_rpn_cls: 0.0001843  loss_rpn_loc: 0.004344    time: 0.1771  last_time: 0.1787  data_time: 0.0022  last_data_time: 0.0029   lr: 0.00024476  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:28:09 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.1494  loss_cls: 0.02155  loss_box_reg: 0.06623  loss_mask: 0.06657  loss_rpn_cls: 5.649e-05  loss_rpn_loc: 0.003024    time: 0.1772  last_time: 0.1697  data_time: 0.0026  last_data_time: 0.0024   lr: 0.00024975  max_mem: 2262M\n",
      "\u001b[32m[08/09 14:28:09 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:02:56 (0.1772 s / it)\n",
      "\u001b[32m[08/09 14:28:09 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:58 (0:00:01 on hooks)\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "import os\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/09 14:28:50 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/miniforge3/envs/detectron2/lib/python3.8/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "import os\n",
    "\n",
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/09 14:28:52 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from ../../datasets/pokemon/v5/valid/_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import time, cv2\n",
    "\n",
    "dataset_dicts = load_coco_json(DATASET_DIR + \"valid/\" +COCO_JSON_FILE_NAME, DATASET_DIR + \"valid\", \"pokemon_train_dataset\")\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3 if len(dataset_dicts)>3 else len(dataset_dicts)):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    # im = cv2.imread(\"../../datasets/pokemon/\" + \"1.jpeg\")\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=pokemon_metadata, \n",
    "                   scale=0.5, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    image_name = str(round(time.time()*1000))+'.jpg'\n",
    "    cv2.imshow(image_name, out.get_image()[:, :, ::-1])\n",
    "    if cv2.waitKey(0) == 27:\n",
    "        break  # esc to quit\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/09 14:19:37 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from ../../datasets/pokemon/v5/valid/_annotations.coco.json\n",
      "\u001b[32m[08/09 14:19:37 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   gengar   | 10           |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[08/09 14:19:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/09 14:19:37 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[08/09 14:19:37 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/09 14:19:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m COCOEvaluator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpokemon_valid\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m build_detection_test_loader(cfg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpokemon_valid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(inference_on_dataset(\u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mmodel, val_loader, evaluator))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# another equivalent way to evaluate the model is to use `trainer.test`\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "evaluator = COCOEvaluator(\"pokemon_valid\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"pokemon_valid\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
